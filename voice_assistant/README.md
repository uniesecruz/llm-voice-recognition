# ğŸ¤– Assistente de Voz com IA

Um assistente de voz completo que utiliza Whisper para reconhecimento de fala, Llama para processamento de linguagem natural e gTTS para sÃ­ntese de voz, tudo orquestrado pelo LangChain.

## ğŸ¯ Funcionalidades

- **Reconhecimento de Voz**: Utiliza OpenAI Whisper via SpeechRecognition para converter fala em texto
- **Processamento de Linguagem**: LLM Llama executando localmente via ctransformers
- **SÃ­ntese de Voz**: Google Text-to-Speech (gTTS) para converter texto em fala
- **Leitura de Texto**: Converte qualquer texto digitado ou arquivo em Ã¡udio
- **OrquestraÃ§Ã£o**: LangChain para gerenciar o fluxo de processamento
- **Interface**: Modo interativo contÃ­nuo, interaÃ§Ãµes Ãºnicas e leitura personalizada
- **Tratamento de Erros**: Sistema robusto de recuperaÃ§Ã£o de falhas
- **ConfiguraÃ§Ãµes**: Volume, velocidade e idioma ajustÃ¡veis

## ğŸ“‹ PrÃ©-requisitos

- Python 3.8 ou superior
- Microfone funcional
- ConexÃ£o com internet (para gTTS)
- Aproximadamente 4GB de espaÃ§o livre em disco (para o modelo Llama)

## ğŸš€ InstalaÃ§Ã£o

### 1. Clone ou baixe o projeto

```bash
git clone <url-do-repositorio>
cd voice_assistant
```

### 2. Crie um ambiente virtual (recomendado)

```bash
python -m venv venv
source venv/bin/activate  # No Windows: venv\\Scripts\\activate
```

### 3. Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

### 4. Baixe o modelo Llama

Execute o script de download do modelo:

```bash
python download_model.py
```

Este processo pode demorar alguns minutos dependendo da sua conexÃ£o com a internet.

## ğŸ® Como Usar

### ExecuÃ§Ã£o Principal

```bash
python main.py
```

O programa apresentarÃ¡ um menu com as seguintes opÃ§Ãµes:

1. **Modo Interativo ContÃ­nuo**: O assistente escuta continuamente e responde Ã s suas perguntas
2. **InteraÃ§Ã£o Ãšnica**: Uma Ãºnica pergunta e resposta
3. **Testar Componentes**: Testa cada componente individualmente
4. **Ler Texto Personalizado**: Converte texto digitado ou arquivos em Ã¡udio
5. **Sair**: Encerra o programa

### Leitura de Texto Personalizado

A nova funcionalidade permite:
- **Texto digitado**: Digite qualquer texto para conversÃ£o em Ã¡udio
- **Arquivo de texto**: Carregue arquivos .txt para leitura em voz alta
- **Exemplo**: Use o arquivo `exemplo_texto.txt` incluÃ­do para teste

### Comandos de Voz para Parar

No modo interativo contÃ­nuo, vocÃª pode dizer qualquer uma dessas palavras para encerrar:
- "parar"
- "sair" 
- "tchau"
- "encerrar"

## ğŸ—ï¸ Estrutura do Projeto

```
voice_assistant/
â”œâ”€â”€ main.py                 # Arquivo principal
â”œâ”€â”€ voice_recognizer.py     # MÃ³dulo de reconhecimento de voz
â”œâ”€â”€ llm_manager.py          # Gerenciador da LLM
â”œâ”€â”€ voice_synthesizer.py    # SÃ­ntese de voz
â”œâ”€â”€ download_model.py       # Script para baixar modelo
â”œâ”€â”€ requirements.txt        # DependÃªncias
â”œâ”€â”€ README.md              # Este arquivo
â””â”€â”€ models/                # Pasta para modelos (criada automaticamente)
    â””â”€â”€ llama-2-7b-chat.Q4_K_M.gguf
```

## ğŸ”§ ConfiguraÃ§Ãµes

### Modelo Whisper

Por padrÃ£o, usa o modelo "base". VocÃª pode alterar no arquivo `main.py`:

```python
self.voice_recognizer = VoiceRecognizer(model_name="small")  # tiny, base, small, medium, large
```

### Idioma da SÃ­ntese

Por padrÃ£o configurado para portuguÃªs brasileiro. Para alterar:

```python
self.voice_synthesizer = VoiceSynthesizer(language='en')  # Para inglÃªs
```

### ParÃ¢metros da LLM

Edite o arquivo `llm_manager.py` para ajustar:

```python
config = {
    'max_new_tokens': 512,      # Tamanho mÃ¡ximo da resposta
    'temperature': 0.7,         # Criatividade (0.0 a 1.0)
    'context_length': 2048,     # Tamanho do contexto
    'repetition_penalty': 1.1,  # Penalidade por repetiÃ§Ã£o
}
```

## ğŸ› ï¸ DependÃªncias Principais

- **speechrecognition**: Interface para reconhecimento de voz
- **openai-whisper**: Modelo de reconhecimento de voz da OpenAI
- **langchain**: Framework para aplicaÃ§Ãµes com LLM
- **ctransformers**: InferÃªncia de modelos transformer em CPU
- **gtts**: Google Text-to-Speech
- **pygame**: ReproduÃ§Ã£o de Ã¡udio
- **pyaudio**: Captura de Ã¡udio do microfone

## ğŸ› SoluÃ§Ã£o de Problemas

### Erro de Microfone

Se houver erro com o microfone:
1. Verifique se o microfone estÃ¡ conectado e funcionando
2. No Windows, verifique as permissÃµes de microfone
3. Teste com outro aplicativo de gravaÃ§Ã£o

### Modelo nÃ£o encontrado

Se aparecer "Modelo LLM nÃ£o encontrado":
1. Execute novamente: `python download_model.py`
2. Verifique se hÃ¡ espaÃ§o suficiente em disco
3. Verifique sua conexÃ£o com a internet

### Erro de Ã¡udio PyAudio

No Windows, se houver erro com PyAudio:
```bash
pip install pipwin
pipwin install pyaudio
```

### SÃ­ntese de voz nÃ£o funciona

1. Verifique sua conexÃ£o com a internet (gTTS precisa de internet)
2. Teste os alto-falantes/fones de ouvido
3. Verifique se o pygame estÃ¡ funcionando

## ğŸ“Š Desempenho

- **Modelo Whisper base**: ~140MB, boa precisÃ£o
- **Modelo Llama Q4_K_M**: ~3.8GB, boa qualidade de resposta
- **Tempo de resposta**: 3-10 segundos dependendo do hardware
- **RAM necessÃ¡ria**: ~4-6GB durante execuÃ§Ã£o

## ğŸ¤ ContribuiÃ§Ãµes

ContribuiÃ§Ãµes sÃ£o bem-vindas! Para contribuir:

1. FaÃ§a um fork do projeto
2. Crie uma branch para sua feature
3. FaÃ§a commit das suas mudanÃ§as
4. FaÃ§a push para a branch
5. Abra um Pull Request

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo LICENSE para mais detalhes.

## ğŸ™ Agradecimentos

- OpenAI pelo modelo Whisper
- Meta pelo modelo Llama
- Google pelo gTTS
- Comunidade LangChain
- Todos os desenvolvedores das bibliotecas utilizadas

---

**Desenvolvido com â¤ï¸ e Python**
